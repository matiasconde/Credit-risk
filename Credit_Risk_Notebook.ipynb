{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  NaN        NaN     5000.0       5000.0           4975.0   36 months   \n",
       "1  NaN        NaN     2500.0       2500.0           2500.0   60 months   \n",
       "2  NaN        NaN     2400.0       2400.0           2400.0   36 months   \n",
       "3  NaN        NaN    10000.0      10000.0          10000.0   36 months   \n",
       "4  NaN        NaN     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade       ...        \\\n",
       "0   10.65%       162.87     B        B2       ...         \n",
       "1   15.27%        59.83     C        C4       ...         \n",
       "2   15.96%        84.33     C        C5       ...         \n",
       "3   13.49%       339.31     C        C1       ...         \n",
       "4   12.69%        67.79     B        B5       ...         \n",
       "\n",
       "  hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "\n",
       "  disbursement_method  debt_settlement_flag debt_settlement_flag_date  \\\n",
       "0                Cash                     N                       NaN   \n",
       "1                Cash                     N                       NaN   \n",
       "2                Cash                     N                       NaN   \n",
       "3                Cash                     N                       NaN   \n",
       "4                Cash                     N                       NaN   \n",
       "\n",
       "  settlement_status settlement_date settlement_amount  settlement_percentage  \\\n",
       "0               NaN             NaN               NaN                    NaN   \n",
       "1               NaN             NaN               NaN                    NaN   \n",
       "2               NaN             NaN               NaN                    NaN   \n",
       "3               NaN             NaN               NaN                    NaN   \n",
       "4               NaN             NaN               NaN                    NaN   \n",
       "\n",
       "  settlement_term  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv('LoanStats3a.csv', skiprows=1,low_memory=False)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loans_2007 = loans_2007.drop(['desc', 'url'],axis=1)\n",
    "# half_count = len(loans_2007) / 2\n",
    "# loans_2007 = loans_2007.dropna(thresh=half_count, axis=1)\n",
    "# loans_2007.to_csv('loans_2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade    ...    last_pymnt_amnt  \\\n",
       "0   10.65%       162.87     B        B2    ...             171.62   \n",
       "1   15.27%        59.83     C        C4    ...             119.66   \n",
       "2   15.96%        84.33     C        C5    ...             649.91   \n",
       "3   13.49%       339.31     C        C1    ...             357.48   \n",
       "4   12.69%        67.79     B        B5    ...              67.79   \n",
       "\n",
       "  last_credit_pull_d collections_12_mths_ex_med  policy_code application_type  \\\n",
       "0           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "1           Sep-2013                        0.0          1.0       INDIVIDUAL   \n",
       "2           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "3           Apr-2016                        0.0          1.0       INDIVIDUAL   \n",
       "4           Jun-2016                        0.0          1.0       INDIVIDUAL   \n",
       "\n",
       "  acc_now_delinq chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies  \\\n",
       "0            0.0                      0.0         0.0                  0.0   \n",
       "1            0.0                      0.0         0.0                  0.0   \n",
       "2            0.0                      0.0         0.0                  0.0   \n",
       "3            0.0                      0.0         0.0                  0.0   \n",
       "4            0.0                      0.0         0.0                  0.0   \n",
       "\n",
       "  tax_liens  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans_2007 = pd.read_csv(\"loans_2007.csv\",low_memory=False)\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST STEP: FEATURE PREPARATION\n",
    "#### Looking at the csv file\n",
    "\n",
    "The csv file contains 52 columns, we are going to examine in groups of 18.\n",
    "\n",
    "We are going to pay attention to any column that: \n",
    "\n",
    "- leak information from the future (after the loan has already been funded):\n",
    "This information comes from the credit evolution (comes from the future after that the loans is  funded; this information is never available for the investor.\n",
    "- don't affect a borrower's ability to pay back a loan (e.g. a randomly generated ID value by Lending Club).\n",
    "- formatted poorly and need to be cleaned up.\n",
    "- require more data or a lot of processing to turn into a useful feature.\n",
    "- contain redundant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------------------------------------------------------------------------\n",
    "###### FIRST GROUP OF 18 COLUMNS: \n",
    "\n",
    "\n",
    "-    id: randomly generated field by Lending Club for unique identification purposes only\n",
    "-    member_id: also a randomly generated field by Lending Club for unique identification purposes only\n",
    "-    funded_amnt: leaks data from the future (after the loan is already started to be funded)\n",
    "-    funded_amnt_inv: also leaks data from the future (after the loan is already started to be funded)\n",
    "-    grade: contains redundant information as the interest rate column (int_rate)\n",
    "-    sub_grade: also contains redundant information as the interest rate column (int_rate)\n",
    "-    emp_title: requires other data and a lot of processing to potentially be useful\n",
    "-    issue_d: leaks data from the future (after the loan is already completed funded)\n",
    "++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_to_drop = [\"id\",\"member_id\",\"funded_amnt\",\"funded_amnt_inv\",\"grade\",\"sub_grade\",\"emp_title\",\"issue_d\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_drop,inplace=True,axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SECOND GROUP OF 18 COLUMNS LIST: \n",
    "-    zip_code: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible (which only can be used to identify the state the borrower lives in)\n",
    "-    out_prncp: leaks data from the future, (after the loan already started to be paid off)\n",
    "-    out_prncp_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_pymnt: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_pymnt_inv: also leaks data from the future, (after the loan already started to be paid off)\n",
    "-    total_rec_prncp: also leaks data from the future, (after the loan already started to be paid off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_remove2 = [\"zip_code\",\"out_prncp\",\"out_prncp_inv\",\"total_pymnt\",\"total_pymnt_inv\",\"total_rec_prncp\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_remove2,axis=\"columns\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### THIRD GROUP OF 18 COLUMNS LIST:\n",
    "-    total_rec_int: leaks data from the future, (after the loan already started to be paid off),\n",
    "-   total_rec_late_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    recoveries: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    collection_recovery_fee: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    last_pymnt_d: also leaks data from the future, (after the loan already started to be paid off),\n",
    "-    last_pymnt_amnt: also leaks data from the future, (after the loan already started to be paid off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [loan_amnt, term, int_rate, installment, emp_length, home_ownership, annual_inc, verification_status, loan_status, pymnt_plan, purpose, title, addr_state, dti, delinq_2yrs, earliest_cr_line, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, initial_list_status, last_credit_pull_d, collections_12_mths_ex_med, policy_code, application_type, acc_now_delinq, chargeoff_within_12_mths, delinq_amnt, pub_rec_bankruptcies, tax_liens]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "features_to_drop3 = [\"total_rec_int\",\"total_rec_late_fee\",\"recoveries\",\"collection_recovery_fee\",\"last_pymnt_d\",\"last_pymnt_amnt\"]\n",
    "\n",
    "loans_2007.drop(labels=features_to_drop3,axis=\"columns\",inplace=True)\n",
    "\n",
    "print(loans_2007.head(0))\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECTING THE TARGET COLUMN: \n",
    "\n",
    "- Loan_status it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values and we need to convert it to a numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007[\"loan_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Meaning of the values: \n",
    "\n",
    "- Fully Paid:     Loan has been fully paid off.\n",
    "- Charged Off: \tLoan for which there is no longer a reasonable expectation of further payments.\n",
    "- Does not meet the credit policy: \tWhile the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "\n",
    "\n",
    "- Charged Off: While the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved on to the marketplace.\n",
    "\n",
    "\n",
    "- In Grace Period:\tThe loan is past due but still in the grace period of 15 days.\n",
    "- Late (16-30 days):\tLoan hasn't been paid in 16 to 30 days (late on the current payment). \n",
    "- Late (31-120 days):\tLoan hasn't been paid in 31 to 120 days (late on the current payment).\n",
    "- Current: \tLoan is up to date on current payments.\n",
    "- Default: \tLoan is defaulted on and no payment has been made for more than 121 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Only the Fully Paid and Charged Off values describe the final outcome of the loan. The other values describe loans that are still on going and where the jury is still out on if the borrower will pay back the loan on time or not. While the Default status resembles the Charged Off status, in Lending Club's eyes, loans that are charged off have essentially no chance of being repaid while default ones have a small chance. You can read about the difference here.\n",
    "\n",
    "Since we're interested in being able to predict which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. Let's remove all the loans that don't contain either Fully Paid and Charged Off as the loan's status and then transform the Fully Paid values to 1 for the positive case and the Charged Off values to 0 for the negative case.<i/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.loc[(loans_2007[\"loan_status\"]==\"Fully Paid\")|(loans_2007[\"loan_status\"]==\"Charged Off\")]\n",
    "\n",
    "mapping_dict = {\"loan_status\":{\"Fully Paid\":1,\"Charged Off\":0}}\n",
    "\n",
    "loans_2007.replace(to_replace=mapping_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look for any columns that contain only one unique value and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens']\n"
     ]
    }
   ],
   "source": [
    "drop_columns = []\n",
    "\n",
    "for column in loans_2007.columns:\n",
    "    serie = loans_2007[column]\n",
    "    serie.dropna(inplace=True)\n",
    "    uniques = serie.unique()\n",
    "    if len(uniques)<=1:\n",
    "        drop_columns.append(column)\n",
    "        \n",
    "loans_2007.drop(labels=drop_columns,axis=1,inplace=True)\n",
    "\n",
    "print(drop_columns)\n",
    "\n",
    "loans = loans_2007.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                 0\n",
      "term                      0\n",
      "int_rate                  0\n",
      "installment               0\n",
      "emp_length                0\n",
      "home_ownership            0\n",
      "annual_inc                0\n",
      "verification_status       0\n",
      "loan_status               0\n",
      "purpose                   0\n",
      "title                    10\n",
      "addr_state                0\n",
      "dti                       0\n",
      "delinq_2yrs               0\n",
      "earliest_cr_line          0\n",
      "inq_last_6mths            0\n",
      "open_acc                  0\n",
      "pub_rec                   0\n",
      "revol_bal                 0\n",
      "revol_util               50\n",
      "total_acc                 0\n",
      "last_credit_pull_d        2\n",
      "pub_rec_bankruptcies    697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "null_counts = loans.isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### While most of the columns have 0 missing values, 2 columns have 50 or less rows with missing values, and 1 column, pub_rec_bankruptcies, contains 697 rows with missing values. Let's remove columns entirely where more than 1% of the rows for that column contain a null value. In addition, we'll remove the remaining rows containing null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "loans.drop(labels=[\"pub_rec_bankruptcies\"],inplace=True,axis=1)\n",
    "\n",
    "loans.dropna(how=\"any\",axis=0,inplace=True)\n",
    "\n",
    "print(loans.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The object columns that contain text need to be converted to numerical data types. Let's return a new Dataframe containing just the object columns so we can explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         term int_rate emp_length home_ownership verification_status  \\\n",
      "0   36 months   10.65%  10+ years           RENT            Verified   \n",
      "1   60 months   15.27%   < 1 year           RENT     Source Verified   \n",
      "\n",
      "       purpose     title addr_state earliest_cr_line revol_util  \\\n",
      "0  credit_card  Computer         AZ         Jan-1985      83.7%   \n",
      "1          car      bike         GA         Apr-1999       9.4%   \n",
      "\n",
      "  last_credit_pull_d  \n",
      "0           Jun-2016  \n",
      "1           Sep-2013  \n"
     ]
    }
   ],
   "source": [
    "object_columns_df = loans.select_dtypes(include=[object])\n",
    "\n",
    "print(object_columns_df[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some of the columns seem like they represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    "-    home_ownership: home ownership status, can only be 1 of 4 categorical values according to the data dictionary,\n",
    "-    verification_status: indicates if income was verified by Lending Club,\n",
    "-    emp_length: number of years the borrower was employed upon time of application,\n",
    "-    term: number of payments on the loan, either 36 or 60,\n",
    "-    addr_state: borrower's state of residence,\n",
    "-    purpose: a category provided by the borrower for the loan request,\n",
    "-    title: loan title provided the borrower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i> <b>Based on the first row's values for purpose and title, it seems like these columns could reflect the same information.\n",
    "<i/></b>\n",
    "\n",
    "\n",
    "Some meanings:\n",
    "\n",
    "- int_rate: interest rate of the loan in %.\n",
    "- revol_util: revolving line utilization rate or the amount of credit the borrower is using relative to all available credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18513\n",
      "MORTGAGE    17112\n",
      "OWN          2984\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16696\n",
      "Verified           12290\n",
      "Source Verified     9722\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1229\n",
      "n/a          1032\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    29041\n",
      " 60 months     9667\n",
      "Name: term, dtype: int64\n",
      "CA    6958\n",
      "NY    3713\n",
      "FL    2791\n",
      "TX    2667\n",
      "NJ    1798\n",
      "IL    1483\n",
      "PA    1473\n",
      "VA    1376\n",
      "GA    1364\n",
      "MA    1301\n",
      "OH    1179\n",
      "MD    1026\n",
      "AZ     850\n",
      "WA     822\n",
      "CO     770\n",
      "NC     753\n",
      "CT     730\n",
      "MI     712\n",
      "MO     671\n",
      "MN     603\n",
      "NV     481\n",
      "SC     462\n",
      "WI     441\n",
      "AL     437\n",
      "OR     436\n",
      "LA     430\n",
      "KY     315\n",
      "OK     290\n",
      "KS     260\n",
      "UT     254\n",
      "AR     237\n",
      "DC     209\n",
      "RI     196\n",
      "NM     184\n",
      "WV     172\n",
      "NH     166\n",
      "HI     166\n",
      "DE     113\n",
      "MT      83\n",
      "WY      80\n",
      "AK      78\n",
      "SD      61\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "NE       5\n",
      "IA       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = ['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    print(loans[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The home_ownership, verification_status, emp_length, term, and addr_state columns all contain multiple discrete values. We should clean the emp_length column and treat it as a numerical one since the values have ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_consolidation    18130\n",
      "credit_card            5039\n",
      "other                  3864\n",
      "home_improvement       2897\n",
      "major_purchase         2155\n",
      "small_business         1762\n",
      "car                    1510\n",
      "wedding                 929\n",
      "medical                 680\n",
      "moving                  576\n",
      "vacation                375\n",
      "house                   369\n",
      "educational             320\n",
      "renewable_energy        102\n",
      "Name: purpose, dtype: int64\n",
      "Debt Consolidation                                  2104\n",
      "Debt Consolidation Loan                             1632\n",
      "Personal Loan                                        642\n",
      "Consolidation                                        494\n",
      "debt consolidation                                   485\n",
      "Credit Card Consolidation                            353\n",
      "Home Improvement                                     346\n",
      "Debt consolidation                                   324\n",
      "Small Business Loan                                  310\n",
      "Credit Card Loan                                     305\n",
      "Personal                                             302\n",
      "Consolidation Loan                                   251\n",
      "Home Improvement Loan                                234\n",
      "personal loan                                        227\n",
      "personal                                             211\n",
      "Loan                                                 208\n",
      "Wedding Loan                                         201\n",
      "Car Loan                                             195\n",
      "consolidation                                        193\n",
      "Other Loan                                           181\n",
      "Credit Card Payoff                                   150\n",
      "Wedding                                              149\n",
      "Credit Card Refinance                                143\n",
      "Major Purchase Loan                                  139\n",
      "Consolidate                                          125\n",
      "Medical                                              118\n",
      "Credit Card                                          115\n",
      "home improvement                                     107\n",
      "My Loan                                               92\n",
      "Credit Cards                                          91\n",
      "                                                    ... \n",
      "D's wedding expenses                                   1\n",
      "High interest Credit card payoff                       1\n",
      "MCP Home Improvement Loan                              1\n",
      "Consolidating Credit Cards with 30% APR!               1\n",
      "Consolidating 2 20+% interest Cards                    1\n",
      "Getting a new place                                    1\n",
      "For debts, moving expenses and a cushion               1\n",
      "boat and debt consolidation                            1\n",
      "AmEx                                                   1\n",
      "welding equipment                                      1\n",
      "Furniture Purchase                                     1\n",
      "Moving lending club loan                               1\n",
      "Dads Loan                                              1\n",
      "Get our of debt                                        1\n",
      "To heck with Credit Cards - you get my interest!       1\n",
      "I need a better rate                                   1\n",
      "Loan for Service as a Software startup                 1\n",
      "Ash CC loan                                            1\n",
      "Refinance of High Interest Credit Cards                1\n",
      "Helping Local Small Businesses                         1\n",
      "Best Bang for your Buck                                1\n",
      "faith                                                  1\n",
      "Financial Overhaul                                     1\n",
      "debt con one                                           1\n",
      "Bright Future                                          1\n",
      "Poulsbo                                                1\n",
      "consolidating credit card and loan                     1\n",
      "SRM                                                    1\n",
      "A Smart Move                                           1\n",
      "Debt compression!                                      1\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Purpose and title looking the best column to use: \n",
    "print(loans[\"purpose\"].value_counts())\n",
    "print(loans[\"title\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>It seems like the purpose and title columns do contain overlapping information but we'll keep the purpose column since it contains a few discrete values. In addition, the title column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation)\n",
    "\n",
    "\n",
    "The home_ownership, verification_status, emp_length, and term columns each contain a few discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "\n",
    "We erred on the side of being conservative with the 10+ years, < 1 year and n/a mappings. We assume that people who may have been working more than 10 years have only really worked for 10 years. We also assume that people who've worked less than a year or if the information is not available that they've worked for 0. This is a general heuristic but it's not perfect.\n",
    "\n",
    "The addr_state column contains many discrete values and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger and could slow down how quickly the code runs. Let's remove this column from consideration.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require a good amount of feature engineering for them to be potentially useful:\n",
    "\n",
    "    earliest_cr_line: The month the borrower's earliest reported credit line was opened,\n",
    "    last_credit_pull_d: The most recent month Lending Club pulled credit for this loan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We can use the following mapping to clean the emp_length column:\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "loans.drop(labels=[\"last_credit_pull_d\",\"addr_state\",\"title\",\"earliest_cr_line\"],axis=1,inplace=True)\n",
    "\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(float)\n",
    "\n",
    "loans.replace(to_replace=mapping_dict,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's now encode the home_ownership, verification_status, purpose, and term columns as dummy \n",
    "#variables so we can use them in our model. We first need to use the Pandas get_dummies.\n",
    "df_dummies = pd.get_dummies(loans[[\"home_ownership\",\"verification_status\",\"purpose\",\"term\"]])\n",
    "\n",
    "loans.drop(labels=[\"home_ownership\",\"verification_status\",\"purpose\",\"term\"],axis=1,inplace=True)\n",
    "\n",
    "loans = pd.concat([loans,df_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As we prepared the data, we removed columns that had data leakage issues, contained \n",
    "#redundant information, or required additional processing to turn into useful features. \n",
    "# We cleaned features that had formatting issues, and converted categorical columns to dummy variables.\n",
    "\n",
    "loans.to_csv(\"cleaned_loans_2007.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL STEP: TESTING MODELS\n",
    "\n",
    "##### Objective: build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not. standpoint of a conservative investor.\n",
    "\n",
    "- Rmemember: there's a class imbalance in our target column, loan_status. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with many machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models.\n",
    "This causes a major issue when we use accuracy as a metric. This is because due to the class imbalance, a classifier can predict 1 for every row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38708 entries, 0 to 38707\n",
      "Data columns (total 39 columns):\n",
      "Unnamed: 0                             38708 non-null int64\n",
      "loan_amnt                              38708 non-null float64\n",
      "int_rate                               38708 non-null float64\n",
      "installment                            38708 non-null float64\n",
      "emp_length                             38708 non-null int64\n",
      "annual_inc                             38708 non-null float64\n",
      "loan_status                            38708 non-null int64\n",
      "dti                                    38708 non-null float64\n",
      "delinq_2yrs                            38708 non-null float64\n",
      "inq_last_6mths                         38708 non-null float64\n",
      "open_acc                               38708 non-null float64\n",
      "pub_rec                                38708 non-null float64\n",
      "revol_bal                              38708 non-null float64\n",
      "revol_util                             38708 non-null float64\n",
      "total_acc                              38708 non-null float64\n",
      "home_ownership_MORTGAGE                38708 non-null int64\n",
      "home_ownership_NONE                    38708 non-null int64\n",
      "home_ownership_OTHER                   38708 non-null int64\n",
      "home_ownership_OWN                     38708 non-null int64\n",
      "home_ownership_RENT                    38708 non-null int64\n",
      "verification_status_Not Verified       38708 non-null int64\n",
      "verification_status_Source Verified    38708 non-null int64\n",
      "verification_status_Verified           38708 non-null int64\n",
      "purpose_car                            38708 non-null int64\n",
      "purpose_credit_card                    38708 non-null int64\n",
      "purpose_debt_consolidation             38708 non-null int64\n",
      "purpose_educational                    38708 non-null int64\n",
      "purpose_home_improvement               38708 non-null int64\n",
      "purpose_house                          38708 non-null int64\n",
      "purpose_major_purchase                 38708 non-null int64\n",
      "purpose_medical                        38708 non-null int64\n",
      "purpose_moving                         38708 non-null int64\n",
      "purpose_other                          38708 non-null int64\n",
      "purpose_renewable_energy               38708 non-null int64\n",
      "purpose_small_business                 38708 non-null int64\n",
      "purpose_vacation                       38708 non-null int64\n",
      "purpose_wedding                        38708 non-null int64\n",
      "term_ 36 months                        38708 non-null int64\n",
      "term_ 60 months                        38708 non-null int64\n",
      "dtypes: float64(12), int64(27)\n",
      "memory usage: 11.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv(\"cleaned_loans_2007.csv\")\n",
    "\n",
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNTING TYPE OF ERROS (REMEMBER): \n",
    "\n",
    "tn = ((predictions==0)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "tp = ((predictions==1)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fp = ((predictions==1)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "fn = ((predictions==0)&(loans[\"loan_status\"]==1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We established that this is a binary classification problem\n",
    "\n",
    "#### Error Metrics :\n",
    "In this case, we're primarily concerned with false positives and false negatives. In the first one we are go to loose money, in the second one we loose the possibilitie of win money. The true positivies and true negatives are the coorect predictions and don't contribute to the error metric. \n",
    "\n",
    "<I> conservative investor would want to minimize risk, and avoid false positives as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we should optimize for:\n",
    "\n",
    "-   high recall (true positive rate) --> tpr = tp / (tp + fn)\n",
    "-   low fall-out (false positive rate) --> fpr = fp / (fp + tn)-\n",
    "\n",
    "\n",
    "-    False Positive Rate -- \"what percentage of my 1 predictions are incorrect?\"\n",
    " -       In this case, \"what percentage of the loans that I fund would not be repaid?\"\n",
    "-  True Positive Rate -- \"what percentage of all the possible 1 predictions am I making?\"\n",
    "   -     In this case, \"what percentage of loans that could be funded would I fund?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "#Supose that we predict all ones: \n",
    "#Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(np.ones(loans.shape[0]))\n",
    "\n",
    "tn = ((predictions==0)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "tp = ((predictions==1)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fp = ((predictions==1)&(loans[\"loan_status\"]==0)).sum()\n",
    "\n",
    "fn = ((predictions==0)&(loans[\"loan_status\"]==1)).sum()\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>both metrics are 1: all rows to one, we predict correctly all tp but fn = 0 (because there is no predictions-value 0!\n",
    "also there is no predictions value for tnSames with fp because there is not 0's!) then both ratios are fp/fp and tp/tp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Logistics regressions because: \n",
    "\n",
    "  -   it's quick to train and we can iterate more quickly,\n",
    "  -  it's less prone to overfitting than more complex models like decision trees,\n",
    "  - it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = loans.drop(\"loan_status\",axis=1)\n",
    "target = loans[\"loan_status\"]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(features,target)\n",
    "predictions = lr.predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.970080142476 0.990813767262\n"
     ]
    }
   ],
   "source": [
    "# In order to get a realistic depiction of the accuracy of the model, let's perform k-fold cross validation. \n",
    "# We can use the cross_val_predict() function from the sklearn.model_selection package\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Theory:\n",
    "\n",
    "We'll look into oversampling and undersampling first. They involve taking a sample that contains equal numbers of rows where loan_status is 0, and where loan_status is 1. This way, the classifier is forced to make actual predictions, since predicting all 1s or all 0s will only result in 50% accuracy at most.\n",
    "\n",
    "The downside of this technique is that since it has to preserve an equal ratio, you have to either:\n",
    "\n",
    "    - Throw out many rows of data. If we wanted equal numbers of rows where loan_status is 0 and where loan_status is 1, one way we could do that is to delete rows where loan_status is 1.\n",
    "    - Copy rows multiple times. One way to equalize the 0s and 1s is to copy rows where loan_status is 0.\n",
    "    - Generate fake data. One way to equalize the 0s and 1s is to generate new rows where loan_status is 0.\n",
    "    \n",
    "Unfortunately, none of these techniques are especially easy. The second method we mentioned earlier, telling the classifier to penalize certain rows more, is actually much easier to implement using scikit-learn.\n",
    "\n",
    "We can do this by setting the class_weight parameter to balanced when creating the LogisticRegression instance. This tells scikit-learn to penalize the misclassification of the minority class during the training process. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where loan_status is 0. This lowers accuracy when loan_status is 1, but raises accuracy when loan_status is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "###### By setting the class_weight parameter to balanced, the penalty is set to be inversely proportional to the class frequencies. You can read more about the parameter here. This would mean that for the classifier, correctly classifying a row where loan_status is 0 is 6 times more important than correctly classifying a row where loan_status is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.409082813891 0.632490254737\n"
     ]
    }
   ],
   "source": [
    "#Again with data-set balanced\n",
    "\n",
    "lr = LogisticRegression(class_weight = \"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We significantly improved false positive rate in the last screen by balancing the classes, which reduced true positive rate. Our true positive rate is now around 67%, and our false positive rate is around 40%.\n",
    "###### We want to reduce more the fpr, then we can assign manually the penalties: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.409082813891 0.632490254737\n"
     ]
    }
   ],
   "source": [
    "#Again with manual penalties:\n",
    "\n",
    "penalty = {0:10,1:1}\n",
    "\n",
    "lr = LogisticRegression(class_weight = \"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(lr,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It looks like assigning manual penalties lowered the false positive rate to 7%, and thus lowered our risk. Note that this comes at the expense of true positive rate. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "### TRYING ANOTHER MODEL:\n",
    "###### Random forests are able to work with nonlinear data, and learn complex conditionals. Logistic regressions are only able to work with linear data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.636153161175 0.648777687124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1,class_weight=\"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(rf,features,target,cv=3)\n",
    "\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "tp = ((predictions==1)&(target==1)).sum()\n",
    "tn = ((predictions==0)&(target==0)).sum()\n",
    "fp = ((predictions==1)&(target==0)).sum()\n",
    "fn = ((predictions==0)&(target==1)).sum()\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSIONS:\n",
    "<i><r>\n",
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 7%, and a true positive rate of 20%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 7% of borrowers defaulting, and that the pool of 20% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve:\n",
    "\n",
    "    We can tweak the penalties further.\n",
    "    We can try models other than a random forest and logistic regression.\n",
    "    We can use some of the columns we discarded to generate better features.\n",
    "    We can ensemble multiple models to get more accurate predictions.\n",
    "    We can tune the parameters of the algorithm to achieve higher performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
